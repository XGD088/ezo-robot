import gradio as gr
import requests
import json
import sseclient

def get_available_models():
    """
    è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
    """
    try:
        response = requests.get("http://localhost:8000/models")
        if response.status_code == 200:
            print(f"è·å–æ¨¡å‹åˆ—è¡¨æˆåŠŸ: {response.json()}")
            return response.json()["models"]
        return ["qwen", "deepseek"]  # é»˜è®¤æ¨¡å‹åˆ—è¡¨ï¼Œåƒé—®æ’åœ¨å‰é¢
    except Exception as e:
        print(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}")
        return ["qwen", "deepseek"]  # é»˜è®¤æ¨¡å‹åˆ—è¡¨ï¼Œåƒé—®æ’åœ¨å‰é¢

def chat_with_bot(message, history, model_name):
    """
    ä¸åç«¯APIäº¤äº’çš„å‡½æ•°
    """
    try:
        # å‘é€è¯·æ±‚å¹¶è·å–SSEæµ
        response = requests.post(
            "http://localhost:8000/chat",
            json={
                "message": message,
                "model_name": model_name
            },
            stream=True,
            headers={'Accept': 'text/event-stream'}
        )
        
        if response.status_code == 200:
            # åˆ›å»ºSSEå®¢æˆ·ç«¯
            client = sseclient.SSEClient(response)
            full_response = ""
            
            # å¤„ç†æ¯ä¸ªäº‹ä»¶
            for event in client.events():
                if event.data:
                    try:
                        data = json.loads(event.data)
                        if "response" in data:
                            full_response += data["response"]
                            # ä½¿ç”¨ yield è¿”å›æ›´æ–°åçš„å†å²è®°å½•
                            yield history + [[message, full_response]]
                    except json.JSONDecodeError:
                        # å¦‚æœæ•°æ®ä¸æ˜¯JSONæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ•°æ®
                        full_response += event.data
                        yield history + [[message, full_response]]
        else:
            yield history + [[message, f"é”™è¯¯: {response.json()['detail']}"]]
    except Exception as e:
        yield history + [[message, f"å‘ç”Ÿé”™è¯¯: {str(e)}"]]

# è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
available_models = get_available_models()

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ¤– AI èŠå¤©åŠ©æ‰‹")
    gr.Markdown("è¿™æ˜¯ä¸€ä¸ªæ”¯æŒå¤šæ¨¡å‹çš„AIèŠå¤©åŠ©æ‰‹ã€‚è¯·é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹ï¼Œç„¶åå¼€å§‹å¯¹è¯ã€‚")
    
    with gr.Row():
        # è®¾ç½®é»˜è®¤é€‰æ‹©ä¸ºé€šä¹‰åƒé—®æ¨¡å‹
        default_model = "qwen" if "qwen" in available_models else available_models[0]
        model_dropdown = gr.Dropdown(
            choices=available_models,
            value=default_model,
            label="é€‰æ‹©æ¨¡å‹"
        )
    
    chatbot = gr.Chatbot(
        height=600,
        show_label=False,
        show_share_button=False,
        show_copy_button=True,
        layout="bubble",
    )
    
    with gr.Row():
        msg = gr.Textbox(
            label="è¾“å…¥æ¶ˆæ¯",
            placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...",
            lines=3
        )
        send = gr.Button("å‘é€")
    
    with gr.Row():
        clear = gr.Button("æ¸…é™¤å¯¹è¯")
        retry = gr.Button("é‡è¯•")
        undo = gr.Button("æ’¤é”€")
    
    gr.Examples(
        examples=[
            ["ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"],
            ["ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"],
            ["ä½ èƒ½å¸®æˆ‘å†™ä¸€ä¸ªPythonç¨‹åºå—ï¼Ÿ"]
        ],
        inputs=msg
    )
    
    # äº‹ä»¶å¤„ç†
    send.click(
        chat_with_bot,
        inputs=[msg, chatbot, model_dropdown],
        outputs=chatbot,
        show_progress=True  # æ˜¾ç¤ºè¿›åº¦æ¡
    ).then(
        lambda: "",
        None,
        msg
    )
    
    clear.click(lambda: None, None, chatbot)
    undo.click(lambda x: x[:-1], chatbot, chatbot)
    retry.click(
        lambda x, y, z: chat_with_bot(x[-1][0], x[:-1], z),
        inputs=[chatbot, msg, model_dropdown],
        outputs=chatbot,
        show_progress=True  # æ˜¾ç¤ºè¿›åº¦æ¡
    )

# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        inbrowser=True
    ) 